# Copyright 2024 Iosif Sakos

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

module IterableSchemes

import LinearAlgebra: I as IdentityMatrix, pinv
import StaticArrays: SVector, MVector, MMatrix
import Zygote: pullback, withjacobian

import .._AG, .._ABG, ..payoff, .._AIS
import ..BaseGames: _BG

import ..Utilities: zeros as _zeros


export LatentGradientAscent


@doc raw"""
    LatentGradientAscent{M, G <: AbstractBaseGame} <: AbstractIterableScheme{G}

Gradient ascent scheme for a base game of type `G` and input length `M`.

---

    LatentGradientAscent(Î“::AbstractBaseGame, Î¸â‚€[, Î³]; <keyword arguments>)

Construct a `LatentGradientAscent{sum(size(Î“)), typeof(Î“)}` with step size `Î³` initialized at the strategy profile `Î¸â‚€`.

The scheme is designed to provide optimal last-iterate convergence to the set of Nash equilibria of ``Î“`` under the assumption the corresponding latent game is strongly monotone.

# Extended Help

At each iteration ``t``, the scheme features a gradient step from the current strategy profile ``Î¸â‚œ âˆˆ Î˜â‚ Ã— â‹¯ Ã— Î˜â‚™`` to a new strategy profile ``Î¸â‚œâ‚Šâ‚`` given, for each player ``i = 1, â€¦, n``, by the formula:
```math
  [Î¸â‚œâ‚Šâ‚]áµ¢ = [Î¸â‚œ]áµ¢ + Î³ [ğâ‚œ]áµ¢  âˆ‡_{Î¸áµ¢} uáµ¢(Î¸) \big|_{Î¸ = Î¸â‚œ},
```
where ``uáµ¢(Î¸)`` is the player's payoff at the strategy profile ``Î¸`` in ``Î“``, and ``[ğâ‚œ]áµ¢`` is a preconditioning matrix given by the formula: 
```math
    [ğâ‚œ]áµ¢ = \big(ğ‰áµ¢([Î¸â‚œ]áµ¢) ğ‰áµ¢([Î¸â‚œ]áµ¢)áµ€\big)âº, 
```
where ``ğ‰áµ¢`` is the Jacobian matrix of the player's representation map ``Ï‡áµ¢ : Î˜áµ¢ â†’ ğ’³áµ¢``.

If the payoff function ``uá´´áµ¢: ğ’³â‚ Ã— â‹¯ Ã— ğ’³â‚™ â†’ â„`` of ``i`` in the latent game is known, then ``[Î¸â‚œâ‚Šâ‚]áµ¢`` is equivalent to:
```math
  [Î¸â‚œâ‚Šâ‚]áµ¢ = [Î¸â‚œ]áµ¢ + Î³ ğ‰áµ¢([Î¸â‚œ]áµ¢)âº âˆ‡_{xáµ¢} uá´´áµ¢(x) \big|_{xâ‚ = Ï‡â‚([Î¸â‚œ]â‚), â€¦, xâ‚™ = Ï‡â‚™([Î¸â‚œ]â‚™)}.
```
The latter formula features improved computational stability over the former one.

# Arguments
- `atol = 0`: Absolute tolerance assumed for the computation of the Moore-Penrose inverse.
"""
struct LatentGradientAscent{M, G <: _ABG} <: _AIS{G}
  Î“::G
  Î¸â‚€::MVector{M, Float64}
  Î³
  atol
  function LatentGradientAscent(Î“::G, Î¸â‚€, Î³=1e-4; 
    atol=0
  ) where {S, G <: _AG{S}}
    new{sum(S), G}(Î“, Î¸â‚€, Î³, atol)
  end
end
const _LGA = LatentGradientAscent # alias

Base.iterate(s::_LGA) = (s.Î¸â‚€, convert(SVector, s.Î¸â‚€))

function Base.iterate(s::_LGA{<: Any, <: _BG}, Î¸â‚œâ‚‹â‚)
  bg_sz = size(s.Î“)
  hg_sz = size(s.Î“.Î“) 
  n = length(bg_sz)

  Î˜ = Iterators.Stateful(Î¸â‚œâ‚‹â‚)
  O = Tuple(
    withjacobian(Ï‡áµ¢, Iterators.take(Î˜, máµ¢) |> collect) 
    for (Ï‡áµ¢, máµ¢) âˆˆ zip(s.Î“.Ï‡, bg_sz)
  )
  âˆ‚Ï‡â‚œâ‚‹â‚ = Tuple(Oáµ¢.grad |> only for Oáµ¢ âˆˆ O)

  xâ‚œâ‚‹â‚ = MVector{sum(hg_sz), Float64}(reduce(vcat, Oáµ¢.val for Oáµ¢ âˆˆ O))
  _, âˆ‚hu = pullback(payoff, s.Î“.Î“, xâ‚œâ‚‹â‚)
  IM = MMatrix{n, n, Int}(IdentityMatrix)
  I = Iterators.Stateful(Base.OneTo(sum(hg_sz)))
  âˆ‚uâ‚œâ‚‹â‚ = reduce(vcat, begin 
    (_, âˆ‚huáµ¢) = âˆ‚hu(IMáµ¢) 
    pinv(âˆ‚Ï‡áµ¢; atol=s.atol) * âˆ‚huáµ¢[Iterators.take(I, dáµ¢) |> collect]
  end for (âˆ‚Ï‡áµ¢, dáµ¢, IMáµ¢) âˆˆ zip(âˆ‚Ï‡â‚œâ‚‹â‚, hg_sz, eachcol(IM)))

  Î¸â‚œ = Î¸â‚œâ‚‹â‚ + s.Î³ * âˆ‚uâ‚œâ‚‹â‚
  convert(MVector, Î¸â‚œ), convert(SVector, Î¸â‚œ)
end

Base.eltype(::_LGA{M, <: Any}) where {M} = MVector{M, Float64}


end # module IterableSchemes